# goit-de-hw-04

Висновки з наведеного прикладу з використанням Spark:

1. **Ліниве виконання Spark**: Spark виконує трансформації над даними ліниво, тобто обчислення відбуваються лише тоді, коли виконується дія (action), така як `collect()`, `count()`, або `show()`. Це означає, що без виклику дії Spark лише формує план виконання (DAG) без реального обчислення.

2. **Кількість Jobs залежить від дій**: Кожен виклик дії призводить до створення нового Job, який виконує весь ланцюжок трансформацій, починаючи від вихідного джерела даних. При додаванні додаткової дії без кешування Spark повторює обчислення з самого початку, що збільшує кількість Jobs.

3. **Кешування (`cache()`) зменшує кількість обчислень**: Використання `.cache()` дозволяє Spark зберегти проміжні результати обчислень у пам'яті, що запобігає повторному виконанню трансформацій. Це значно зменшує кількість Jobs, оскільки повторні дії можуть використовувати вже кешовані дані.

4. **Оптимізація за допомогою кешування**: Кешування допомагає покращити продуктивність і зменшити час обчислення, оскільки Spark не потрібно повторно виконувати ті ж самі обчислення при кожній новій дії. Використання кешування особливо корисне, коли один і той же DataFrame використовується у кількох діях.

5. **Звільнення пам'яті з `.unpersist()`**: Після виконання дій над кешованими даними слід звільняти пам'ять, використовуючи `.unpersist()`. Це допомагає оптимізувати використання ресурсів, звільнивши кешовані дані, які більше не потрібні.

6. **Зменшення кількості Job з 8 до 7**: Використання `.cache()` зменшило кількість Job у прикладі з 8 до 7, оскільки Spark повторно використав кешовані проміжні результати, замість того, щоб повторно виконувати всі трансформації з самого початку для кожної нової дії.
